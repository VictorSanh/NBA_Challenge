{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Classifier :\n",
    "**Classifier on 4 best models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from src.utils import split_train_val, feature_engineering\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
    "from keras import losses\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open files\n",
    "Data_X_train = pd.read_csv('data/challenge_fichier_dentrees_dentrainement_challenge_nba/train.csv')\n",
    "Data_Y_train = pd.read_csv('data/challenge_fichier_de_sortie_dentrainement_challenge_nba.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_X_train = feature_engineering(Data_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_games, col = Data_X_train.shape\n",
    "nb_features = int((col-1)/1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = Data_X_train.as_matrix()[:,1:]\n",
    "Y = Data_Y_train.as_matrix()[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split train/val**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "portion_train = 0.7\n",
    "n_train = int(portion_train*nb_games)\n",
    "n_val = nb_games - n_train\n",
    "id_train = np.random.choice(nb_games, n_train, replace=False)\n",
    "\n",
    "# Def train and validation data\n",
    "X_train = X[id_train,:]\n",
    "Y_train = Y[id_train,:].reshape(n_train,)\n",
    "X_val = np.delete(X, id_train, axis = 0)\n",
    "Y_val = np.delete(Y, id_train, axis = 0).reshape(n_val,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_games_train = len(X_train)\n",
    "nb_games_val = len(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost, Random Forest & Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate by 10 seconds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_end = X_train[:,15829]\n",
    "\n",
    "X_train_models = X_train.reshape((nb_games_train, nb_features, 10, -1), order = 'F')\n",
    "X_train_models = X_train_models.mean(axis = 2)\n",
    "X_train_models = X_train_models.reshape(nb_games_train, nb_features*144)\n",
    "\n",
    "# Add final score\n",
    "X_train_tot = np.zeros((X_train_models.shape[0],X_train_models.shape[1]+1))\n",
    "X_train_tot[:,:-1] = X_train_models\n",
    "X_train_tot[:,-1] = score_end\n",
    "\n",
    "## Validation\n",
    "score_end_val = X_val[:,15829]\n",
    "\n",
    "X_val_models = X_val.reshape((nb_games_val, nb_features, 10, -1), order = 'F')\n",
    "X_val_models = X_val_models.mean(axis = 2)\n",
    "X_val_models = X_val_models.reshape(nb_games_val, nb_features*144)\n",
    "\n",
    "# Add final score\n",
    "X_val_tot = np.zeros((X_val_models.shape[0],X_val_models.shape[1]+1))\n",
    "X_val_tot[:,:-1] = X_val_models\n",
    "X_val_tot[:,-1] = score_end_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': 200, 'max_depth': None, 'max_features': 15, \n",
    "               'min_samples_split': 15, 'min_samples_leaf': 2, 'bootstrap': True, \n",
    "               'oob_score': True, 'criterion': 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RandomForest = RandomForestClassifier(**parameters)\n",
    "RandomForest.fit(X_train_tot, Y_train)\n",
    "Y_pred_RandomForest = RandomForest.predict(X_val_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = GradientBoostingClassifier(max_depth=10, n_estimators = 1000)\n",
    "xgb.fit(X_train_tot, Y_train)\n",
    "Y_pred_xgb = xgb.predict(X_val_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=0.00001)\n",
    "LR.fit(X_train_tot, Y_train)\n",
    "Y_pred_LR = LR.predict(X_val_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-directional_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_lstm = X_train.reshape((nb_games_train, nb_features, 15, -1), order = 'F')\n",
    "X_train_lstm = X_train_lstm.mean(axis = 2)\n",
    "Y_train_lstm = np_utils.to_categorical(Y_train, 2)\n",
    "\n",
    "X_val_lstm = X_val.reshape((nb_games_val, nb_features, 15, -1), order = 'F')\n",
    "X_val_lstm = X_val_lstm.mean(axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bi_lstm_model = Sequential()\n",
    "bi_lstm_model.add(Bidirectional(LSTM(125, recurrent_dropout = 0.25), \n",
    "                                input_shape = (16, 96)))\n",
    "bi_lstm_model.add(Dropout(0.75))\n",
    "bi_lstm_model.add(Dense(units = 150, \n",
    "                        activation = 'relu'))\n",
    "bi_lstm_model.add(Dropout(0.5))\n",
    "bi_lstm_model.add(Dense(units = 2, \n",
    "                        activation='softmax'))\n",
    "bi_lstm_model.compile(loss = losses.categorical_crossentropy,\n",
    "                      optimizer = 'adam',\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "#Training\n",
    "bi_lstm_model.fit(X_train_lstm, Y_train_lstm, \n",
    "                  epochs = 15, batch_size = 64, verbose = False)\n",
    "\n",
    "extract_cnn_features = K.function([bi_lstm_model.layers[0].input, K.learning_phase()],\n",
    "                                  [bi_lstm_model.layers[3].output])\n",
    "X_train_features = extract_cnn_features([X_train_lstm, 0])[0]\n",
    "X_test_features = extract_cnn_features([X_test_lstm, 0])[0]\n",
    "\n",
    "parameters = {'n_estimators': 500, 'max_depth': 40, 'min_samples_leaf': 2}\n",
    "clf = RandomForestClassifier(**parameters)\n",
    "clf.fit(X_train_features, Y_train.ravel())\n",
    "\n",
    "Y_pred_lstm = clf.predict(X_val_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = np.column_stack((Y_pred_RandomForest, Y_pred_LR, Y_pred_xgb, Y_pred_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = [0.00001 , 0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10, 100, 1000]\n",
    "for c in C :\n",
    "    LR = LogisticRegression(C=c)\n",
    "    LR.fit(Y_pred, Y_val)\n",
    "    print(LR.score(Y_pred,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
