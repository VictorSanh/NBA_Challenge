{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Classifier :\n",
    "**Classifier on 4 best models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from src.utils import split_train_val, feature_engineering\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
    "from keras import losses\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files\n",
    "Data_X_train = pd.read_csv('data/challenge_fichier_dentrees_dentrainement_challenge_nba/train.csv')\n",
    "Data_Y_train = pd.read_csv('data/challenge_fichier_de_sortie_dentrainement_challenge_nba.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_X_train = feature_engineering(Data_X_train, two_points = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_games, col = Data_X_train.shape\n",
    "nb_features = int((col-1)/1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Data_X_train.as_matrix()[:,1:]\n",
    "Y = Data_Y_train.as_matrix()[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split train/val**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "portion_train = 0.7\n",
    "n_train = int(portion_train*nb_games)\n",
    "n_val = nb_games - n_train\n",
    "id_train = np.random.choice(nb_games, n_train, replace=False)\n",
    "\n",
    "# Def train and validation data\n",
    "X_train = X[id_train,:]\n",
    "Y_train = Y[id_train,:].reshape(n_train,)\n",
    "X_val = np.delete(X, id_train, axis = 0)\n",
    "Y_val = np.delete(Y, id_train, axis = 0).reshape(n_val,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_games_train = len(X_train)\n",
    "nb_games_val = len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Data_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost, Random Forest & Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate by 10 seconds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_end = X_train[:,25903]\n",
    "\n",
    "X_train_models = X_train.reshape((nb_games_train, nb_features, 10, -1), order = 'F')\n",
    "X_train_models = X_train_models.mean(axis = 2)\n",
    "X_train_models = X_train_models.reshape(nb_games_train, nb_features*144)\n",
    "\n",
    "# Add final score\n",
    "X_train_tot = np.zeros((X_train_models.shape[0],X_train_models.shape[1]+1))\n",
    "X_train_tot[:,:-1] = X_train_models\n",
    "X_train_tot[:,-1] = score_end\n",
    "\n",
    "## Validation\n",
    "score_end_val = X_val[:,25903]\n",
    "\n",
    "X_val_models = X_val.reshape((nb_games_val, nb_features, 10, -1), order = 'F')\n",
    "X_val_models = X_val_models.mean(axis = 2)\n",
    "X_val_models = X_val_models.reshape(nb_games_val, nb_features*144)\n",
    "\n",
    "# Add final score\n",
    "X_val_tot = np.zeros((X_val_models.shape[0],X_val_models.shape[1]+1))\n",
    "X_val_tot[:,:-1] = X_val_models\n",
    "X_val_tot[:,-1] = score_end_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_models, X_val_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': 200, 'max_depth': None, 'max_features': 15, \n",
    "               'min_samples_split': 15, 'min_samples_leaf': 2, 'bootstrap': True, \n",
    "               'oob_score': True, 'criterion': 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 97.01 - Val: 73.65\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(**parameters)\n",
    "RandomForest.fit(X_train_tot, Y_train)\n",
    "\n",
    "acc_train, acc_val = RandomForest.score(X_train_tot, Y_train), RandomForest.score(X_val_tot, Y_val)\n",
    "print('Train: {0:.2f} - Val: {1:.2f}'.format(100*acc_train, 100*acc_val))\n",
    "\n",
    "Y_pred_RandomForest = RandomForest.predict(X_val_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 100.00 - Val: 73.18\n"
     ]
    }
   ],
   "source": [
    "xgb = GradientBoostingClassifier(max_depth=10, n_estimators = 1000)\n",
    "xgb.fit(X_train_tot, Y_train)\n",
    "\n",
    "acc_train, acc_val = xgb.score(X_train_tot, Y_train), xgb.score(X_val_tot, Y_val)\n",
    "print('Train: {0:.2f} - Val: {1:.2f}'.format(100*acc_train, 100*acc_val))\n",
    "\n",
    "Y_pred_xgb = xgb.predict(X_val_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 73.74 - Val: 71.59\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(C=0.0001)\n",
    "LR.fit(X_train_tot, Y_train)\n",
    "\n",
    "acc_train, acc_val = LR.score(X_train_tot, Y_train), LR.score(X_val_tot, Y_val)\n",
    "print('Train: {0:.2f} - Val: {1:.2f}'.format(100*acc_train, 100*acc_val))\n",
    "\n",
    "Y_pred_LR = LR.predict(X_val_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-directional_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm = X_train.reshape((nb_games_train, nb_features, 15, -1), order = 'F')\n",
    "X_train_lstm = X_train_lstm.mean(axis = 2)\n",
    "Y_train_lstm = np_utils.to_categorical(Y_train, 2)\n",
    "\n",
    "X_val_lstm = X_val.reshape((nb_games_val, nb_features, 15, -1), order = 'F')\n",
    "X_val_lstm = X_val_lstm.mean(axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 99.59 - Val: 73.50\n"
     ]
    }
   ],
   "source": [
    "bi_lstm_model = Sequential()\n",
    "bi_lstm_model.add(Bidirectional(LSTM(175, recurrent_dropout = 0.25), \n",
    "                                input_shape = (18, 96)))\n",
    "bi_lstm_model.add(Dropout(0.75))\n",
    "bi_lstm_model.add(Dense(units = 150, \n",
    "                        activation = 'relu'))\n",
    "bi_lstm_model.add(Dropout(0.5))\n",
    "bi_lstm_model.add(Dense(units = 2, \n",
    "                        activation='softmax'))\n",
    "bi_lstm_model.compile(loss = losses.categorical_crossentropy,\n",
    "                      optimizer = 'adam',\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "#Training\n",
    "bi_lstm_model.fit(X_train_lstm, Y_train_lstm, \n",
    "                  epochs = 15, batch_size = 64, verbose = False)\n",
    "\n",
    "extract_cnn_features = K.function([bi_lstm_model.layers[0].input, K.learning_phase()],\n",
    "                                  [bi_lstm_model.layers[3].output])\n",
    "X_train_features = extract_cnn_features([X_train_lstm, 0])[0]\n",
    "X_val_features = extract_cnn_features([X_val_lstm, 0])[0]\n",
    "\n",
    "parameters = {'n_estimators': 500, 'max_depth': 40, 'min_samples_leaf': 2}\n",
    "clf = RandomForestClassifier(**parameters)\n",
    "clf.fit(X_train_features, Y_train.ravel())\n",
    "\n",
    "acc_train, acc_val = clf.score(X_train_features, Y_train), clf.score(X_val_features, Y_val)\n",
    "print('Train: {0:.2f} - Val: {1:.2f}'.format(100*acc_train, 100*acc_val))\n",
    "\n",
    "Y_pred_lstm = clf.predict(X_val_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1e-05 - Train: 71.93 +/-0.61 - Val: 71.93 +/-2.43\n",
      "C=0.0001 - Train: 72.20 +/-0.40 - Val: 72.17 +/-2.81\n",
      "C=0.0005 - Train: 73.71 +/-0.65 - Val: 73.71 +/-2.61\n",
      "C=0.001 - Train: 73.71 +/-0.65 - Val: 73.71 +/-2.61\n",
      "C=0.005 - Train: 73.83 +/-0.61 - Val: 73.79 +/-2.55\n",
      "C=0.01 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=0.1 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=0.5 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=1 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "Uniform Mean Score: 72.33\n"
     ]
    }
   ],
   "source": [
    "Y_preds = np.column_stack((Y_pred_RandomForest, Y_pred_LR, Y_pred_xgb, Y_pred_lstm))\n",
    "\n",
    "C = [0.00001 , 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 0.5, 1]\n",
    "for c in C :\n",
    "    LR = LogisticRegression(C=c)\n",
    "    scores = cross_validate(LR, Y_preds, Y_val, cv = 5, return_train_score = True)\n",
    "    print('C={0} - Train: {1:.2f} +/-{2:.2f} - Val: {3:.2f} +/-{4:.2f}'.format(c,\n",
    "                                                                              100*np.mean(scores['train_score']),\n",
    "                                                                              100*np.std(scores['train_score']),\n",
    "                                                                              100*np.mean(scores['test_score']),\n",
    "                                                                              100*np.std(scores['test_score'])))\n",
    "print('Uniform Mean Score: {:.2f}'.format(100*np.mean(Y_preds.mean(axis=1).astype(int)==Y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1e-05 - Train: 73.26 +/-0.62 - Val: 73.26 +/-2.47\n",
      "C=0.0001 - Train: 73.26 +/-0.62 - Val: 73.26 +/-2.47\n",
      "C=0.0005 - Train: 73.65 +/-0.52 - Val: 73.63 +/-2.95\n",
      "C=0.001 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=0.005 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=0.01 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=0.1 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=0.5 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=1 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "Uniform Mean Score: 73.20\n"
     ]
    }
   ],
   "source": [
    "Y_preds = np.column_stack((Y_pred_RandomForest, Y_pred_xgb, Y_pred_lstm))\n",
    "\n",
    "C = [0.00001 , 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 0.5, 1]\n",
    "for c in C :\n",
    "    LR = LogisticRegression(C=c)\n",
    "    scores = cross_validate(LR, Y_preds, Y_val, cv = 5, return_train_score = True)\n",
    "    print('C={0} - Train: {1:.2f} +/-{2:.2f} - Val: {3:.2f} +/-{4:.2f}'.format(c,\n",
    "                                                                              100*np.mean(scores['train_score']),\n",
    "                                                                              100*np.std(scores['train_score']),\n",
    "                                                                              100*np.mean(scores['test_score']),\n",
    "                                                                              100*np.std(scores['test_score'])))\n",
    "print('Uniform Mean Score: {:.2f}'.format(100*np.mean(Y_preds.mean(axis=1).astype(int)==Y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1e-05 - Train: 69.43 +/-3.32 - Val: 69.86 +/-4.93\n",
      "C=0.0001 - Train: 72.32 +/-1.42 - Val: 72.43 +/-4.48\n",
      "C=0.0005 - Train: 73.55 +/-0.63 - Val: 73.57 +/-2.65\n",
      "C=0.001 - Train: 73.87 +/-0.61 - Val: 73.97 +/-2.51\n",
      "C=0.005 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=0.01 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=0.1 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=0.5 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n",
      "C=1 - Train: 73.87 +/-0.64 - Val: 73.87 +/-2.56\n"
     ]
    }
   ],
   "source": [
    "Y_preds = np.column_stack((Y_pred_RandomForest, Y_pred_xgb, Y_pred_lstm, score_end_val))\n",
    "\n",
    "C = [0.00001 , 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 0.5, 1]\n",
    "for c in C :\n",
    "    LR = LogisticRegression(C=c)\n",
    "    scores = cross_validate(LR, Y_preds, Y_val, cv = 5, return_train_score = True)\n",
    "    print('C={0} - Train: {1:.2f} +/-{2:.2f} - Val: {3:.2f} +/-{4:.2f}'.format(c,\n",
    "                                                                              100*np.mean(scores['train_score']),\n",
    "                                                                              100*np.std(scores['train_score']),\n",
    "                                                                              100*np.mean(scores['test_score']),\n",
    "                                                                              100*np.std(scores['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.81162191,  0.70716802,  0.84358252, -0.0025334 ]]),\n",
       " array([-1.21358256]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "#Save Logistic Regression on top of other predictions\n",
    "Y_preds = np.column_stack((Y_pred_RandomForest, Y_pred_xgb, Y_pred_lstm, score_end_val))\n",
    "LR = LogisticRegression(C=c)\n",
    "LR.fit(Y_preds, Y_val)\n",
    "joblib.dump(LR, 'models/Log_Reg_On_Other_Clfs_Predictions.pkl')\n",
    "LR.coef_, LR.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
